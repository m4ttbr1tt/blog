[{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":0,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":1,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":2,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":3,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":4,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":5,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":6,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage. \u0026lt;\u0026ndash;more\u0026ndash;\u0026gt;\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"18 May, 2025","id":7,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"","tags":"homelab storage","title":"Adding storage to our homelab application."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":0,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":1,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":2,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":3,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":4,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":5,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":6,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage. \u0026lt;\u0026ndash;more\u0026ndash;\u0026gt;\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"18 May, 2025","id":7,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"","tags":"homelab storage","title":"Adding storage to our homelab application."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":0,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":1,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":2,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":3,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":4,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":5,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":6,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage. \u0026lt;\u0026ndash;more\u0026ndash;\u0026gt;\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"17 May, 2025","id":7,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"","tags":"homelab storage","title":"Adding storage to our homelab application."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":0,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":1,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":2,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":3,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":4,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":5,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":6,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage. \u0026lt;\u0026ndash;more\u0026ndash;\u0026gt;\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"17 May, 2025","id":7,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"","tags":"homelab storage","title":"Adding storage to our homelab application."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":0,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":1,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":2,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":3,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":4,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":5,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":6,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":7,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":8,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":9,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":10,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":11,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage. \u0026lt;\u0026ndash;more\u0026ndash;\u0026gt;\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"1 January, 0001","id":12,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"","tags":"homelab storage","title":"Adding storage to our homelab application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":0,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":1,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":2,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":3,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":4,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":5,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":6,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage. \u0026lt;\u0026ndash;more\u0026ndash;\u0026gt;\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"17 May, 2025","id":7,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"","tags":"homelab storage","title":"Adding storage to our homelab application."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"14 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"14 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist or data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi ","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\napiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo!\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding persistent storage for our application."},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\napiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo!\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generate be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding storage to our homelab application"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\n# apiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\napiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo!\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding storage to our homelab application"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\n#base/linkding/pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\n#base/linkding/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo!\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding storage to our homelab application"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\n#base/linkding/pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\n#base/linkding/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo!\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding storage to our homelab application"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\n#base/linkding/pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it the container.\n#base/linkding/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo! üí•\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding storage to our homelab application"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\n#base/linkding/pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it to the container.\n#base/linkding/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo! üí•\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding storage to our homelab application"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.\nFirst we need to provision a PVC.\n#base/linkding/pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: linkding-pv-claim namespace: linkding spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi And then alter our deployment to add the volume and mount it to the container.\n#base/linkding/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding volumes: - name: linkding-pv-storage persistentVolumeClaim: claimName: linkding-pv-claim template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 volumeMounts: - mountPath: \u0026#34;/usr/share/linkding\u0026#34; name: linkding-pv-storage With Flux running in our cluster all we need to do is to commit and push our changes to the homelab repo! üí•\n","date":"18 June, 2025","id":0,"permalink":"/posts/adding-storage-to-our-homelab-application/","summary":"In order to persist any data that will be generated be linkding, we need to make sure that we have persistent storage.","tags":"homelab k3s GitOps","title":"Adding storage to our homelab application"},{"content":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.\nhttps://linkding.link/\nWays to structure your git repo Flux has some recommendations on how to structure your git repo. For my homelab I\u0026rsquo;ll be using the below structure.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ infrastructure ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging ‚îî‚îÄ‚îÄ clusters ‚îú‚îÄ‚îÄ production ‚îî‚îÄ‚îÄ staging For details and alternatives you can see more details here\u0026hellip;\nhttps://fluxcd.io/flux/guides/repository-structure\nKustomization file Flux has a kustomization file that reads in other kustomize files (its the entry point)\nAny Kustomization file in the clusters \u0026gt; staging dir will be included.\nFlux app config file Add this file to clusters \u0026gt; staging (it is configured to look in the ./apps/staging path that we are setting up in the next step)\n# apps.yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: apps namespace: flux-system spec: interval: 1m retryInterval: 1m timeout: 1m sourceRef: kind: GitRepository name: flux-system path: ./apps/staging # references the dir just setup prune: true Base layers Shared config is stored in base layers and then overridden in derived layers with a patches definition.\nEg.\n‚îú‚îÄ‚îÄ apps ‚îÇ ‚îú‚îÄ‚îÄ base ‚îÇ ‚îú‚îÄ‚îÄ production ‚îÇ ‚îî‚îÄ‚îÄ staging Adding an app Kustomization file mkdir -p apps/staging/linkding mkdir -p apps/base/linkding cd apps/staging/linkding touch kustomization.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: linkding resources: - ../.../base/linkding # reads in base config directory cd apps/base/linkding touch kustomization.yaml touch namespace.yaml touch deployment.yaml # kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - namespace.yaml - deployment.yaml # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: linkding # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: linkding spec: replicas: 1 selector: matchLabels: app: linkding template: metadata: labels: app: linkding spec: containers: - name: linkding image: sissbruecker/linkding:1.31.0 ports: - containerPort: 9090 Once pushed to git you can check the status by running the below command. Once the cluster state has been reconciled, you will see the state change (or you will receive a notification of any failures)\nflux get kustomizations And then port forward to check that the app is running.\nkubectl port-forward linkding-pod 8080:9090 #8080 is localport 9090 is the port exposed by deployment We will be setting up a service to manage this soon. Until next time üòç\nhttps://github.com/m4ttbr1tt/homelab\n","date":"14 June, 2025","id":1,"permalink":"/posts/installing-our-first-homelab-application-with-gitops/","summary":"After setting up Flux on the cluster, its time to put it to use! I\u0026rsquo;ll be deploying an app called Linkding, which is a bookmark manager.","tags":"homelab k3s GitOps","title":"Installing our first homelab application with GitOps"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo.\nI\u0026rsquo;ve chosen Flux for the following reasons:\nKustomize is used by default (Application customisation) CLI focused (Argo has a great UI, but Id rather not use that) Used by default in Azure AKS (which is what I know) https://fluxcd.io\nInstalling Flux First create a personal token on GitHub and export the token, as well as your GitHub username, as an environment variable.\nexport GITHUB_TOKEN=ghp_234234234234234234234 export GITHUB_USER=m4ttbr1tt Next check your cluster meets the prerequisites\u0026hellip;\nflux check --pre ..and install Flux.\n# will install to cluster and then push manifests to github flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=homelab \\ --branch=master \\ --path=./clusters/staging \\ --personal You will now see Flux pods on the cluster\u0026hellip; https://github.com/m4ttbr1tt/homelab\n","date":"11 June, 2025","id":2,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":3,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":4,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab I\u0026rsquo;ve completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":5,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":6,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":7,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":8,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":9,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":10,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":11,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":12,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"}]