[{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":1,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":2,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":3,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":4,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":5,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":6,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":7,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":8,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Ive completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"Ive completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":1,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":2,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":3,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":4,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":5,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":6,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":7,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":8,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":1,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":2,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":3,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":4,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":5,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":6,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":7,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":8,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"9 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"9 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"9 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"3 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"3 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":1,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":2,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":3,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":4,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":5,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":6,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":7,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":8,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":0,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"3 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of K3S onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server The secret is a shared secret supplied (not the token) # random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config ![[Pasted image 20250610070041.png]]\nUninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling # servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cabinet](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ![cluster](/posts/homelab-high-availability-k3s-cluster/cluster.png) ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane ## first server curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional Server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret pO0RP3kYa1M0xQrF6h2sQ3dT5ekpprhpc4SVHGShZcS5glG Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\n# random supplied secret touch secret vim secret somerandomsecret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply to each machine, and when other control plane or agent nodes join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply the same to each machine, and when other control plane or agent nodes join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines The secret is a shared secret you need to supply the same secret to each machine, and when other control plane or agent nodes join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine, when other control plane or agent nodes join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initial install and when other control plane or agent nodes join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and when other control plane or agent nodes join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # connect host to remote cluster # remote server sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit the IP mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane --cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . exit # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh ","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\n","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":0,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":1,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":2,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":3,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":4,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":5,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":6,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":7,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":8,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":9,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? ","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? ","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? ","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? ","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? ","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? ","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and was difficult to maintain, and there was often drift or uncertainty as to what the state of the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, and there was often drift or uncertainty as to what the state of the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain,there was often drift or uncertainty as to what the state of the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to what the state of the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state of the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state of the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"},{"content":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.\nWhat is GitOps? GitOps is a best practice for code delivery of applications and infrastructure. It uses git as the source of truth and a controller that runs on the cluster, constantly checking the git repo for any changes and reconciling the declared state with the cluster.\nGitOps enables declarative cluster state\nWhen I first used Kubernetes in production in 2018, we did not have GitOps. The deployments and manifests were written in bash scripts and it was difficult to maintain, there was often drift or uncertainty as to the state of the cluster was in. GitOps is a modern way to resolve this, and its beautiful üòç.\nWhich GitOps tool to choose? There are two main tools in this space Flux and Argo\n","date":"11 June, 2025","id":0,"permalink":"/posts/homelab-gitops-with-flux/","summary":"Today I installed Flux onto the cluster in order to implement GitOps for my homelab.","tags":"homelab k3s GitOps","title":"GitOps with Flux"},{"content":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!\nNode IP Role Notes molly 192.168.1.51 control plane \u0026ndash;cluster-init daisy 192.168.1.52 control plane joins molly rosie 192.168.1.53 control plane joins molly bessy 192.168.1.54 worker joins any server elsie 192.168.1.55 worker joins any server Secret for all machines You need to supply the same secret to each machine! The initially installed control plane and other control planes or agent nodes need the same secret to join the cluster.\necho \u0026#34;somerandomsecret\u0026#34; \u0026gt; secret Install the initial control plane curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --cluster-init \\ --disable=helm-controller sudo systemctl status k3s.service Additional server installs curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - server \\ --server https://192.168.1.51:6443 \\ --disable=helm-controller Agent install curl -sfL https://get.k3s.io | K3S_TOKEN=$(cat secret) sh -s - agent --server https://192.168.1.51:6443 Connecting to cluster # remote control plane sudo cp /etc/rancher/k3s/k3s.yaml . # On main system scp matt@192.168.1.51:/home/matt/k3s.yaml . vim k3s.yaml # edit IP to point to control plane mkdir ~/.kube mv k3s.yaml .kube/config Uninstalling In case you need to uninstall..\n# servers /usr/local/bin/k3s-uninstall.sh # agents /usr/local/bin/k3s-agent-uninstall.sh Done! üòç\nNext will be setting up Flux for GitOps!\n","date":"10 June, 2025","id":1,"permalink":"/posts/homelab-high-availability-k3s-cluster/","summary":"I\u0026rsquo;ve completed the install of a high availability K3S cluster onto the 5 Optiplex machines. Had one or two issues, that meant I had to reinstall with a new secret, but otherwise was pretty smooth!","tags":"homelab k3s","title":"Homelab high availability K3S cluster install"},{"content":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.\nI will be running a K3S cluster initially and then upgrading to used TalosOS at a later stage. Ill be using GitOps to track the state of the cluster, so the migration to Talos should be easy.I setup the machines with the below network config (static ip addresses)\nvim /etc/netplan/99_config.yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.51/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [1.1.1.1] Machine Names The initial laptop that I ran a test cluster on was one of my daughters, and it had cow stickers all over it, so for better or worse here are my machines and their ips.\nmolly 192.168.1.51 daisy 192.168.1.52 rosie 192.168.1.53 bessy 192.168.1.54 elsie 192.168.1.55 I then applied my changes\u0026hellip;\nsudo netplan apply \u0026hellip;and tested ssh connectivity from my main machine. (I still need to setup dns)\nssh matt@192.168.1.51 We are ready to get the cluster installed and running!\nI crimped some Cat5e connectors too! Not done that in a while üòÄ\n","date":"7 June, 2025","id":2,"permalink":"/posts/homelab-kickoff-host-provisioning/","summary":"To start the homelab Ive completed the installation of Ubuntu Server onto the 5 Dell Optiplex mini-pcs that will be running my Kubernetes homelab.","tags":"homelab k3s","title":"Homelab kickoff - host provisioning"},{"content":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.\nThe layout of the partitions and volumes will look like this:\nThe size of the SSD is 128GB so I\u0026rsquo;ll be arranging the partitions/volumes like below:\ncat /proc/meminfo # how much memory on the system # Memtotal 8010000 kB = 8GB # So swap will be 4GB (50%) # sda is 128GB # par boot 1GB # par swap 4GB # par root 24GB # par home 90GB GPT (GUID Partition Table)or MBR partition table GPT (GUID Partition Table) is a newer partition table schema that allows for unlimited partitions and larger drives and is used with UEFI firmware, which is a newer version of BIOS. The older MBR (Master Boot Record) partition table is legacy format.\nCheck the system boot type We need to verify that the system is using UEFI firmware, which replaces BIOS, and is typically used with GPT partitions.\n# if the below dir exists its an uefi system ls /sys/firmware/efi To determine the current disk partition table we run:\nfdisk -l # youll see Disklabel type: gpt or dos(mbr) # if there is no partition table or you can create a new one fdisk /dev/vda m # man page g #to create a new GPT partition table Partitioning the Disks We will setup two disk partitions that will be the EFI and LVM partitions. Arch wiki suggests boot partition size of 1GB, and rest of the disk will be for LVM (Logical Volume Manager). LVM allows for more flexible management of disks space and our partitions will be setup within this layer.\nlsblk # list block devices (shows current disk layout) fdisk /dev/vda n # add a new partition #default partition number (default): 1 #first sector (default) : 2048 #last sector: +1G #Change the type filesystem type: t # change file system type 1 # select partition L # show partition types # Set partition type to EFI 1 # create data partition n # new partition #default partition number (default): 2 #first sector (default) : 20992000 #last sector (default): 4000797392 t # change file system type 2 # select partition L # show partition types # Set partition type to Linux LVM 44 p # print partition table w # write changes to the disk fdisk -l Encryption \u0026amp; LVM Using LVM makes managing encryption of the disk more straightforward as you only required one key / password to unlock the data.\n# Create the encrypted container on the Linux LVM partition cryptsetup luksFormat /dev/vda2 YES #Enter the passphrase x 2 and open the disk to setup volumes cryptsetup open /dev/vda2 cryptlvm # Create a PV(physical volume) on-top of the opened luks container pvcreate /dev/mapper/cryptlvm # Next create a disk volume group (we are naming ours phoenix) vgcreate phoenix /dev/mapper/cryptlvm # Next create our logical volumes in the volume group lvcreate -L 4G phoenix -n swap lvcreate -L 24G phoenix -n root lvcreate -L 90G phoenix -n home # show our volumes lvdisplay File systems Now that we have or disk arranged how we have planned, we need to setup a file system on each logical volume, we will be using ext4.\n# setup the file system mkfs.ext4 /dev/phoenix/root mkfs.ext4 /dev/phoenix/home # and the swap mkswap /dev/phoenix1/swap # Prepare the boot partition by making a FAT32 file system mkfs.fat -F32 /dev/vda1 df -h # outputs file systems you have (-h is human readable format) Mounting the volumes For our system to access the new partitions / volumes we need to mount them first.\nOrder of mount matters we must map root, boot and then home.\n# mnt will be the install systems root / directory mount /dev/phoenix/root /mnt mount --mkdir /dev/vda1 /mnt/boot mount /dev/phoenix/home /home # activate the swap partition swapon /dev/phoenix/swap df -h And we are done, we can now processed with setting up our Arch Linux system. When you boot the system you will be prompted to enter your configured password, your data is safe!\n","date":"29 May, 2025","id":3,"permalink":"/posts/arch-linux-disk-partitioning-and-encryption/","summary":"Yesterday I set out to work through getting disk encryption configured on one of the 5 OptiPlex 7040 Mini PCS that arrived yesterday. I will be setting up my homelab with these machines and want to make sure I have mastered the process of disk partitioning and encryption.","tags":"arch","title":"Arch Linux disk partitioning and encryption"},{"content":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.\nI\u0026rsquo;ve setup a dotfiles management solution that is the best I\u0026rsquo;ve had. Credit to Mischa and Rio. It is highly portable across bare-metal and containers.\nChezmoi - dot files manager Its a dotfiles manager that manages the state of your .config directory (it does diffs and applies and state changes), across multiple machines.\nYou can read more about it here https://www.chezmoi.io/\nMise - a development environment setup tool With the mise.toml file you specify the dependencies you would like to install for a specific project, it has template support, secret management with sops and age, and more.\nYou can read more about it here https://mise.jdx.dev/\nDevpod I have integrated these tools with devcontainers to build a declarative, reproducible config environment.\nUsing devpods (https://devpod.sh/) and the hooks it provides for executing scripts, I\u0026rsquo;ve combined these three tools into something that I am very happy with.\nAll credit to Mischa and Rio in the KubeCraft community. Thank you so much.\nHyprland on Arch I\u0026rsquo;m not enjoying the desktop experience on Bluefin. Having worked entirely in a window manager for the last few years, just having tmux as a sudo WM is not enough, I need to be able to be virtually 100% keyboard based, so I\u0026rsquo;m busy figuring out next steps. Likely an Arch \u0026amp; Hyprland iteration, with the aim of a setup that is declarative and reproducible.\n","date":"26 May, 2025","id":4,"permalink":"/posts/bluefin-and-dotfiles-management-changes/","summary":"Last week I decided to ditch NixOS, as it was getting in the way of my work. I\u0026rsquo;ve setup a Fedora based distribution called Bluefin, which went smoothly but has taken some getting used to. There are things that have been great, and some not so much, mainly due to the desktop environment, which I\u0026rsquo;ll need to resolve.","tags":"devpod bluefin","title":"Bluefin and dotfiles management changes"},{"content":"18 months on NixOS‚Ä¶ and I‚Äôm done. I‚Äôm moving to Bluefin. I loved the idea of NixOS, a declarative, reproducible, git tracked OS.\nBut‚Ä¶\nIt distracted me from doing real work When I needed flexibility, it refused (or asked for a time investment to get things done) The OS is not relevant in the DevOps community, even though the package manager has its uses. The final straw was not being able to run DevContainers due to a read-only file system (I could have persisted to sort it out, but I\u0026rsquo;m done now). Its over.\nI\u0026rsquo;m grateful for the time I\u0026rsquo;ve had with the ecosystem, it taught me a lot about what I value in a system.\nI\u0026rsquo;ve also come to realise the exorbitant amount of time I\u0026rsquo;ve sunk into \u0026ldquo;just\u0026rdquo; getting my workstation configured, fancy \u0026ldquo;ricing\u0026rdquo; and tweaks every day! I\u0026rsquo;m done now. I need to focus on doing real work.\nI‚Äôm now trying out Bluefin, which is optimised for containers and cloud-native workflows.\nNo regrets. NixOS taught me a lot, but it‚Äôs time for a change. (although Im keeping my github repo still)\nIll be writing about Bluefin in a future post.\nSome Bluefin Kubernetes CLI goodness\u0026hellip;\n","date":"21 May, 2025","id":5,"permalink":"/posts/18-months-on-nixos-and-im-done-moving-to-bluefin/","summary":"18 months on NixOS‚Ä¶ and I‚Äôm done.  I‚Äôm moving to Bluefin. I loved the idea of NixOS,  a declarative, reproducible, git tracked OS.","tags":"NixOS Bluefin","title":"18 Months on NixOs and Im done! Moving to Bluefin."},{"content":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.\nTo install run the following curl -sfL https://get.k3s.io | sh - There is an interesting output to note after the install, K3S installs a single binary and creates 3 symlinks.\n[INFO] Installing k3s to /usr/local/bin/k3s [INFO] Creating /usr/local/bin/kubectl symlink to k3s [INFO] Creating /usr/local/bin/crictl symlink to k3s [INFO] Creating /usr/local/bin/ctr symlink to k3s Check that the cluster is running sudo k3s kubectl get node K9S is a CLI application that manages your Kubernetes cluster To start K9S run the following k9s --kubeconfig /etc/rancher/k3s/k3s.yaml K9S showing currently running pods on the newly installed K3S cluster:\n","date":"17 May, 2025","id":6,"permalink":"/posts/installing-k3s-and-k9s-on-a-ubuntu-server-vm/","summary":"K3S is a lightweight version of Kubernetes and is used for running on resource constrained environments.","tags":"K9S K3S","title":"Installing K3S and K9S on an Ubuntu Server VM"},{"content":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand. My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.\nDocumenting your learning journey through content creation A learning journey, no matter what the material, would benefit from being documented publicly (if appropriate). It serves as a record for you and the world.\nContent doesn\u0026rsquo;t need to be complicated or original\nAs you are going to be posting your content publicly, it will improve the quality of your note taking, and thus your learning and understanding of a topic. The purpose of the content is information transfer not entertainment, there is no need for literary genius or originality.\nThere is no need to be a perfectionist\nShare everything you learn on various platforms, long format and short. If posting to a blog, then reuse your content on LinkedIn and X.\nMake sure to reuse your own content on each platform\nContent generation, rooted in writing, will create opportunity Writing is an enabling and empowering activity. It will allow you to generate a lot of content to share on a variety of platforms. This will open new opportunities, many of which you can not foresee.\nEverything starts with writing, so take personal notes for everything you learn or consume. (Eg in Obsidian)\nBuilding a Personal Brand Being active in the digital world is critical, especially if you are trying to grow your career in an industry that requires proof of experience and skills, the analog world is becoming less relevant.\nIn order to build a strong online presence, you need to have a personal brand that shows your value to others. Your personal brand is how you want others to perceive you, and this is facilitated through writing and associated content creation.\nA strong personal brand will open opportunities as it will have reach and a large audience. If executed consistently you will be able to leverage this to your benefit.\nJobs will come to you and unexpected things will happen.\n","date":"13 May, 2025","id":7,"permalink":"/posts/building-a-personal-brand/","summary":"In this post, I\u0026rsquo;ve tried to outline the purpose of building an online presence and personal brand.  My goals are to grow my brand as a Software and DevOps engineer, but that doesn\u0026rsquo;t preclude this being used for any other type of career, digital or otherwise.","tags":"brand","title":"Building a Personal Brand"},{"content":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.\nMy journey began in networking and support, before I took time out to study and moved into software engineering. Over the years I was naturally drawn into the world of DevOps, where I‚Äôve found a strong sense of alignment with my interests in systems, automation, and continuous learning.\nWhy this blog, and why now? For most of my career, I‚Äôve chosen to stay relatively private. But the industry is changing, and continues to change, faster than ever. With increasing uncertainty and noise, I‚Äôve realised the importance of having a visible, authentic presence and personal brand.\nThis blog is where I document what I‚Äôm learning, reflect on where I‚Äôve been, and share thoughts on the technologies and practices that matter to me.\nI‚Äôve always been driven by curiosity and a desire to improve.\nWelcome and thanks for your interest ü§©\n","date":"12 May, 2025","id":8,"permalink":"/about/","summary":"Howzit, I‚Äôm Matt Britt. I live in Cape Town, South Africa üáøüá¶üòç. I‚Äôve been working in tech for close to 20 years.","tags":"","title":"Start here. This is my personal README.md"},{"content":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.\nIf you\u0026rsquo;re a professional in DevOps or software engineering, Vim should not be optional.\nThat doesn‚Äôt mean you need to live inside vim or switch to Neovim overnight. Just start with Vim motions, they‚Äôre built into most editors via extensions.\nYou don‚Äôt need ‚Äúfull Vim‚Äù. Use VSCode with the Vim plugin. That‚Äôs more than enough to get the benefits.\nHere‚Äôs why you should start learning it now:\nYou keep your hands on the keyboard, which means less context switching and fewer mouse detours\nYou build deep muscle memory for editing, searching, and refactoring\nFor DevOps and system administration, it‚Äôs essential\nThe learning curve can be steep. But it doesn‚Äôt have to be. Start with just a few motions. Use them until they‚Äôre second nature. Then add more.\nVim is a lifelong multiplier. There‚Äôs no excuse not to start.\n","date":"25 April, 2019","id":9,"permalink":"/posts/why-every-engineer-should-learn-vim/","summary":"I\u0026rsquo;ve been using vim for close to 10 years, in various forms, vim, nvim, vscode extensions.","tags":"","title":"Why every engineer should learn vim"},{"content":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.\nWhenever I made an effort to touch type, my eyes inevitably always drifted down. The keyboard was there, and the temptation was too strong.\nI decided to switch to Dvorak and at the same time I bought a Kinesis Advantage 2.\nDvorak is an alternative keyboard layout which places the most commonly used letters under your strongest fingers and minimises finger movement.\nI wasn\u0026rsquo;t that bothered about comparing to other layouts like Colmak. The Kinesis has Dvorak built in so it made sense.\nBecause I didn‚Äôt know the layout, and more importantly, the keys didn‚Äôt match the labels on the board. Looking down was useless.\nIt was tough! Painfully slow, but I wasn\u0026rsquo;t able to cheat by looking at the keyboard, so I just slogged through and slowly my speeds went up and now I\u0026rsquo;m fully productive!\nThe result? I finally learned to touch type after more than a decade in this career.\nNot just that, it rewired how I work:\nLess cognitive load while coding Less fatigue from hunting keys More confidence in every terminal session Looked more professional! This was one of the best decisions I have made and its be so worthwhile!\n","date":"25 March, 2019","id":10,"permalink":"/posts/dvorak-how-touch-typing-changed-how-i-work/","summary":"After 14 years as a software developer, I still wasn‚Äôt a true touch typist, I would hen-peck my way through my work, I managed but it was not optimal.","tags":"","title":"Dvorak - how touch typing changed how I work"}]